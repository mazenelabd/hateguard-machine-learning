{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[onnx] in c:\\anaconda\\lib\\site-packages (4.27.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\anaconda\\lib\\site-packages (from transformers[onnx]) (23.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in c:\\anaconda\\lib\\site-packages (from transformers[onnx]) (0.13.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\anaconda\\lib\\site-packages (from transformers[onnx]) (0.13.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\anaconda\\lib\\site-packages (from transformers[onnx]) (1.23.4)\n",
      "Requirement already satisfied: filelock in c:\\anaconda\\lib\\site-packages (from transformers[onnx]) (3.0.12)\n",
      "Requirement already satisfied: requests in c:\\anaconda\\lib\\site-packages (from transformers[onnx]) (2.24.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\anaconda\\lib\\site-packages (from transformers[onnx]) (4.65.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\anaconda\\lib\\site-packages (from transformers[onnx]) (5.3.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\anaconda\\lib\\site-packages (from transformers[onnx]) (2020.10.15)\n",
      "Requirement already satisfied: onnxruntime-tools>=1.4.2 in c:\\anaconda\\lib\\site-packages (from transformers[onnx]) (1.7.0)\n",
      "Requirement already satisfied: onnxruntime>=1.4.0 in c:\\anaconda\\lib\\site-packages (from transformers[onnx]) (1.14.1)\n",
      "Requirement already satisfied: tf2onnx in c:\\anaconda\\lib\\site-packages (from transformers[onnx]) (1.14.0)\n",
      "Requirement already satisfied: onnxconverter-common in c:\\anaconda\\lib\\site-packages (from transformers[onnx]) (1.13.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers[onnx]) (3.7.4.3)\n",
      "Requirement already satisfied: sympy in c:\\anaconda\\lib\\site-packages (from onnxruntime>=1.4.0->transformers[onnx]) (1.6.2)\n",
      "Requirement already satisfied: protobuf in c:\\anaconda\\lib\\site-packages (from onnxruntime>=1.4.0->transformers[onnx]) (3.20.2)\n",
      "Requirement already satisfied: flatbuffers in c:\\anaconda\\lib\\site-packages (from onnxruntime>=1.4.0->transformers[onnx]) (2.0.7)\n",
      "Requirement already satisfied: coloredlogs in c:\\anaconda\\lib\\site-packages (from onnxruntime>=1.4.0->transformers[onnx]) (15.0.1)\n",
      "Requirement already satisfied: psutil in c:\\anaconda\\lib\\site-packages (from onnxruntime-tools>=1.4.2->transformers[onnx]) (5.7.2)\n",
      "Requirement already satisfied: onnx in c:\\anaconda\\lib\\site-packages (from onnxruntime-tools>=1.4.2->transformers[onnx]) (1.13.1)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\anaconda\\lib\\site-packages (from onnxruntime-tools>=1.4.2->transformers[onnx]) (9.0.0)\n",
      "Requirement already satisfied: py3nvml in c:\\anaconda\\lib\\site-packages (from onnxruntime-tools>=1.4.2->transformers[onnx]) (0.2.7)\n",
      "Requirement already satisfied: colorama in c:\\anaconda\\lib\\site-packages (from tqdm>=4.27->transformers[onnx]) (0.4.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\anaconda\\lib\\site-packages (from requests->transformers[onnx]) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\anaconda\\lib\\site-packages (from requests->transformers[onnx]) (1.25.11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\anaconda\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda\\lib\\site-packages (from requests->transformers[onnx]) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\anaconda\\lib\\site-packages (from requests->transformers[onnx]) (3.0.4)\n",
      "Requirement already satisfied: six in c:\\anaconda\\lib\\site-packages (from tf2onnx->transformers[onnx]) (1.15.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\anaconda\\lib\\site-packages (from coloredlogs->onnxruntime>=1.4.0->transformers[onnx]) (10.0)\n",
      "Requirement already satisfied: xmltodict in c:\\anaconda\\lib\\site-packages (from py3nvml->onnxruntime-tools>=1.4.2->transformers[onnx]) (0.12.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\anaconda\\lib\\site-packages (from sympy->onnxruntime>=1.4.0->transformers[onnx]) (1.1.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\anaconda\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.4.0->transformers[onnx]) (3.4.1)\n",
      "Requirement already satisfied: onnxruntime in c:\\anaconda\\lib\\site-packages (1.14.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\anaconda\\lib\\site-packages (from onnxruntime) (2.0.7)\n",
      "Requirement already satisfied: protobuf in c:\\anaconda\\lib\\site-packages (from onnxruntime) (3.20.2)\n",
      "Requirement already satisfied: packaging in c:\\anaconda\\lib\\site-packages (from onnxruntime) (23.0)\n",
      "Requirement already satisfied: numpy>=1.21.6 in c:\\anaconda\\lib\\site-packages (from onnxruntime) (1.23.4)\n",
      "Requirement already satisfied: coloredlogs in c:\\anaconda\\lib\\site-packages (from onnxruntime) (15.0.1)\n",
      "Requirement already satisfied: sympy in c:\\anaconda\\lib\\site-packages (from onnxruntime) (1.6.2)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\anaconda\\lib\\site-packages (from coloredlogs->onnxruntime) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\anaconda\\lib\\site-packages (from sympy->onnxruntime) (1.1.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\anaconda\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime) (3.4.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\anaconda\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers[onnx]\n",
    "!pip install onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'microsoft/MiniLM-L12-H384-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 14:10:27.568965: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2023-04-06 14:10:27.569015: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "C:\\anaconda\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "Local PyTorch model found.\n",
      "Framework not requested. Using torch to export to ONNX.\n",
      "Using framework PyTorch: 1.13.1+cpu\n",
      "Overriding 1 configuration item(s)\n",
      "\t- use_cache -> False\n",
      "Validating ONNX model...\n",
      "\t-[\\u2713] ONNX model output names match reference model ({'logits'})\n",
      "\t- Validating ONNX Model output \"logits\":\n",
      "\t\t-[\\u2713] (3, 3) matches (3, 3)\n",
      "\t\t-[\\u2713] all values close (atol: 1e-05)\n",
      "All good, model saved at: onnx/model.onnx\n",
      "C:\\anaconda\\lib\\site-packages\\transformers\\onnx\\__main__.py:178: FutureWarning: The export was done by transformers.onnx which is deprecated and will be removed in v5. We recommend using optimum.exporters.onnx in future. You can find more information here: https://huggingface.co/docs/optimum/exporters/onnx/usage_guides/export_a_model.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "!python -m transformers.onnx --model=data/output/best_model --feature=sequence-classification onnx/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "test_data = pd.read_csv('data/input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweets = test_data['tweet'].to_list()\n",
    "test_labels = test_data['class'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "from onnxruntime import InferenceSession\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "session = InferenceSession(\"onnx/model.onnx\")\n",
    "# ONNX Runtime expects NumPy arrays as input\n",
    "inputs = tokenizer(test_tweets, return_tensors=\"np\", max_length=64, padding=\"max_length\", truncation=True)\n",
    "# convert input data type to int64\n",
    "inputs = {k: v.astype(np.int64) for k, v in inputs.items()}\n",
    "outputs = session.run(output_names=[\"logits\"], input_feed=inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output_labels_1 = np.argmax(outputs[0], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9026632384728706"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_model_1 = f1_score(test_labels, test_output_labels_1, average='weighted')\n",
    "f1_model_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same Model with Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignore MatMul due to non constant B: /[/bert/encoder/layer.0/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/bert/encoder/layer.0/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/bert/encoder/layer.1/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/bert/encoder/layer.1/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/bert/encoder/layer.2/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/bert/encoder/layer.2/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/bert/encoder/layer.3/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/bert/encoder/layer.3/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/bert/encoder/layer.4/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/bert/encoder/layer.4/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/bert/encoder/layer.5/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/bert/encoder/layer.5/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/bert/encoder/layer.6/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/bert/encoder/layer.6/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/bert/encoder/layer.7/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/bert/encoder/layer.7/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/bert/encoder/layer.8/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/bert/encoder/layer.8/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/bert/encoder/layer.9/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/bert/encoder/layer.9/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/bert/encoder/layer.10/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/bert/encoder/layer.10/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/bert/encoder/layer.11/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/bert/encoder/layer.11/attention/self/MatMul_1]\n"
     ]
    }
   ],
   "source": [
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "quantize_dynamic(\"onnx/model.onnx\", \"onnx/model_int8.onnx\", weight_type=QuantType.QUInt8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_int = InferenceSession(\"onnx/model_int8.onnx\")\n",
    "outputs_int = session_int.run(output_names=[\"logits\"], input_feed=inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output_labels_2 = np.argmax(outputs_int[0], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9022992897211402"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_model_2 = f1_score(test_labels, test_output_labels_2, average='weighted')\n",
    "f1_model_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quantization has no significant effect on the model F1 score while reducing the size from 127MB to 32.2MB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
